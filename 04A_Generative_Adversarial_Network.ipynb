{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generative Adversarial Networks**, introduced by Ian Goodfellow in 2014, are neural nets we can train to _produce_ new images (or other kinds of data) that look as though they came from our true data distribution. In this notebook, we'll implement a small GAN for generating images that look as though they come from the MNIST dataset.\n",
    "\n",
    "The key insight behind the GAN is to pit two neural networks against each other. On the one hand is the **Generator**, a neural network that takes random noise as input and produces an image as output. On the other hand is the **Discriminator**, which takes in an image and classifies it as real (from MNIST) or fake (from our Generator). During training, we alternate between training the Generator to fool the Discriminator, and training the Discriminator to call the Generator's bluff.\n",
    "\n",
    "Implementing a GAN in Tensorflow will give you practice turning more involved models into working code, and is also a good showcase for the Keras `Model` abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if running on a GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous examples, we'll use MNIST, because it's a small and easy-to-use dataset that comes bundled with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first provide a simple function for displaying a few 28-by-28-pixel images. This will help us understand the progress of our GAN as it trains; we'll use it to visualize the generated 'fake digit' images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_row(images, img_width=28, cmap='gray'):\n",
    "    \"\"\"\n",
    "    Takes in a tensor of images of given width, and displays them in a column\n",
    "    in a plot, using `cmap` to map from numbers to colors.\n",
    "    \"\"\"\n",
    "    im = np.reshape(images, [-1, img_width])\n",
    "    plt.figure()\n",
    "    plt.imshow(im, cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now set some hyperparameters, for use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph parameters\n",
    "z_dimension = 32\n",
    "intermediate_layer_size = 128\n",
    "image_size = 784\n",
    "# Training parameters\n",
    "batch_size = 50\n",
    "iterations = 25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GAN is made up of two smaller networks: a generator and a discriminator. The generator is responsible for sampling images from a distribution that we hope will get closer and closer, as we train, to the real data distribution.\n",
    "\n",
    "Neural networks are deterministic, so in order to sample a new image from the generator, we first create some random noise `z` (in our case, `z` will be a 32-dimensional uniform random variable) and then feed that noise to the network. You can think of `z` as being a latent, low-dimensional representation of some image `G(z)`, though in a vanilla GAN, it is usually difficult to interpret `z`'s components in a meaningful way.\n",
    "\n",
    "Our generator is a dead-simple multi-layer perceptron (feed-forward network), with 128 hidden units. We use sigmoid activation at the end, to make sure our output pixels are each in the range `[0, 1]` (with 0 as black, and 1 as white).\n",
    "\n",
    "What is new is that here we are using Keras's `Model` abstraction. We are going to write a function `make_generator`, which creates all the relevant weight variables for the generator and adds them to the graph. Then we are going to return a _Model_, `G`, that behaves like a \"graph constructor.\" A user can call `G(z)` with some tensor `z`, and it will add nodes to the graph for computing the fake image from the random noise `z`. Those nodes will do things like matrix multiplies and `relu`s, using the weights that were created when we called `make_generator`. This allows us to _reuse_ `G` with multiple inputs, such that each use of `G` uses the same underlying weights. The Keras `Model` object `G` also has useful properties that we'll need later on -- for example, `G.trainable_variables` gives us access to all the weight variables that were created by `make_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras generator\n",
    "def make_generator():\n",
    "    # This \"z_in\" is a 'symbolic input node' -- do not think of it as belonging to the graph yet.\n",
    "    z_in = tf.keras.layers.Input((z_dimension,))\n",
    "    # This call to `Dense` adds weights and biases to the graph, but does not conceptually add\n",
    "    # matrix multiplication and ReLU yet; that will happen when the generator is applied to an \n",
    "    # actual input tensor later.\n",
    "    hidden_layer = tf.keras.layers.Dense(intermediate_layer_size, activation='relu')(z_in)\n",
    "    # Similarly, this `Dense` just serves to add more weights and biases to the graph\n",
    "    fake_X = tf.keras.layers.Dense(image_size, activation='sigmoid')(hidden_layer)\n",
    "    # The thing we will return is a `Model`. We specify the input and output nodes of \n",
    "    # the generator, and the Model acts as a kind of \"reusable template\" -- when applied to\n",
    "    # different input tensors, it will construct the appropriate matrix multiply and ReLU\n",
    "    # and sigmoid operations for producing `fake_X`.\n",
    "    G = tf.keras.Model(inputs=[z_in], outputs=[fake_X])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it isn't necesssary, it makes some sense for our discriminator to mirror the generator's architecture, as we do here. The discriminator takes in an image (perhaps a real one from the MNIST dataset, perhaps a fake one from our generator), and attempts to classify it as real (1) or fake (0). Our architecture is again a simple MLP, taking 784 pixels down to 128 hidden units, and finally down to a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator():\n",
    "    images_in = tf.keras.layers.Input((image_size,))\n",
    "    hidden_layer = tf.keras.layers.Dense(intermediate_layer_size, activation='relu')(images_in)\n",
    "    D_output = tf.keras.layers.Dense(1, activation='sigmoid')(hidden_layer)\n",
    "    D = tf.keras.Model(inputs=[images_in], outputs=[D_output])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a generator and discriminator, we can now set up the GAN's computational graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# We begin by creating placeholders for the real images and noise, z.\n",
    "real_X = tf.placeholder(tf.float32, [None, image_size])\n",
    "z = tf.placeholder(tf.float32, [None, z_dimension])\n",
    "\n",
    "# We create both the generator and discriminator. This adds weights to \n",
    "# the graph, and returns Model objects D and G that we can apply to \n",
    "# actual tensors.\n",
    "D = make_discriminator()\n",
    "G = make_generator()\n",
    "\n",
    "# Apply the generator to z.\n",
    "fake_X = G(z)\n",
    "\n",
    "# Apply the discriminator to the fake images and the real images\n",
    "d_on_fake = D(fake_X)\n",
    "d_on_real = D(real_X)\n",
    "\n",
    "# Compute the losses\n",
    "g_loss = -tf.reduce_mean(tf.log(d_on_fake + 1e-20))\n",
    "d_loss = -tf.reduce_mean(tf.log(d_on_real + 1e-20) + tf.log(1. - d_on_fake + 1e-20))\n",
    "\n",
    "# Create the two optimization operations\n",
    "optimize_d = tf.train.AdamOptimizer().minimize(d_loss, var_list=D.trainable_variables)\n",
    "optimize_g = tf.train.AdamOptimizer().minimize(g_loss, var_list=G.trainable_variables)\n",
    "\n",
    "# Create the operation that initializes the variables.\n",
    "initialize_all = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training procedure is a bit more involved than in past demos. Here are the main differences:\n",
    "1. Each iteration, we first train the generator, then (separately) the discriminator.\n",
    "2. Each iteration, we need to feed in a batch of images, just as in previous notebooks. But we also need a batch of noise samples. For this, we use Numpy's `np.random.uniform` function.\n",
    "3. Every 1000 iterations, we log some data to the console and visualize a few samples from our generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the GAN.\n",
    "def make_noise():\n",
    "    return np.random.uniform(-1.0, 1.0, [batch_size, z_dimension])\n",
    "\n",
    "def next_feed_dict():\n",
    "    return {real_X: mnist.train.next_batch(batch_size)[0],\n",
    "            z:      make_noise()}\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(initialize_all)\n",
    "\n",
    "start_time = time.time()\n",
    "for t in range(iterations):\n",
    "    sess.run(optimize_g, feed_dict=next_feed_dict())\n",
    "    _, loss = sess.run([optimize_d, d_loss], feed_dict=next_feed_dict())\n",
    "\n",
    "    if t % 1000 == 0 or t+1 == iterations:\n",
    "        fake_data = sess.run(fake_X, feed_dict={z: make_noise()})\n",
    "        print('Iter [%8d] Time [%5.4f] d_loss [%.4f]' % (t, time.time() - start_time, loss))\n",
    "        visualize_row(fake_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions: Playing with GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolating between images\n",
    "\n",
    "As our “random noise” varies, so does the image our GAN generates. Perturbing the random input a little bit should perturb the image a little bit. This means that by taking small steps from one input to another, we can “animate” the transition from the image our GAN draws for the first to the one it draws for the second. Generate two random samples from a GAN, and interpolate between them (with, say, 100 steps).\n",
    "\n",
    "In particular:\n",
    "1. Train a GAN (using code from class).\n",
    "2. Generate some noise `= np.random.uniform(-1, 1, [10, 32])` (for instance).\n",
    "3. Get some fake images out using `sess.run(fake_X, {z: noise})`\n",
    "4. Visualize them using `visualize_row()` and choose two images you like (say, image 1 and 3). Pull out `start` and `end` noise vectors (e.g., `start = noise[0]` and `end = noise[2]`).\n",
    "5. Generate a list of ten vectors `steps = [..., ..., ...]`, where entry `i` is `i*10`% of the way from start to end.\n",
    "6. `np.concatenate(steps)` (with appropriate axis) to get a new noise matrix. Run the GAN on that noise matrix, and visualize the 10 images you get as results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditioning on the class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we drew a random noise vector $z$, and passed it into the Generator. This gave us very little control over the images we generated. Suppose we wanted to be able to generate a random image of a two, or of a three. In other words, we want to train the model to know how to draw whatever digit we tell it to. How could you alter the training procedure to make this work? Implement a conditional GAN, and use it to generate twos or threes.\n",
    "\n",
    "In particular,\n",
    "\n",
    "1. Modify the code from class to take placeholder inputs (real images and z values) that are 10 elements longer.\n",
    "2. Modify the next_feed_dict to concatenate labels (one-hot, ten-dimensional) to the noise inputs and image inputs.\n",
    "3. Train the GAN.\n",
    "4. Try making the GAN generate a few ones, then a few threes, by concatenating `[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]` or `[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]`, say, to your noise vectors. How does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
